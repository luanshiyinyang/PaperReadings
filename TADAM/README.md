# TADAM解读

> 这是最近公开的CVPR2021主会议论文中一篇MOT方向的论文，将位置预测和特征提取两个任务协同工作，从而有效改善了遮挡等问题。

## 简介

目前的多目标跟踪方法主要关注于两个方向来改进跟踪性能，一是基于跟踪信息从之前帧预测当前帧中的位置，二是生成更具判别性的身份嵌入（identity embedding）来增强数据关联。有一些工作将这两个方向组合到一个框架中，但是仍然是将它们视作两个独立的任务，因此获得了很少相互作用的效果。在这篇论文中，作者提出了一种新的具有协同作用的统一模型，它确保了位置预测和嵌入关联之间的协同工作。这两个任务是通过时间感知目标注意力和干扰物注意力以及身份感知记忆聚合模型链接到一起的。具体而言，注意力模块确保预测更加关注于目标而不是干扰物，因而更具可靠性的嵌入可以提取用于关联。另一方面，这种可靠的嵌入可以通过记忆聚合增强身份感知能力从而增强注意力模块并且抑制漂移。通过这种方式，位置预测和嵌入关联协同作用，增强了跟踪器对于遮挡的鲁棒性。实验表明，提出的TADAM在MOTChallenge上领先于现有的大多数跟踪方法，获得了SOTA的表现。

- 论文标题

    Online Multiple Object Tracking with Cross-Task Synergy
- 论文地址

    https://arxiv.org/abs/2104.00380
- 论文源码

    https://github.com/songguocode/TADAM

## 介绍

多目标跟踪（MOT）任务目的在于在每一帧中定位目标并且保持其身份标识以形成跨帧轨迹。目前MOT领域的研究主要集中在TBD范式下，也就是将多目标跟踪问题分为两个步骤，首先是每帧上检测出所有目标，然后通过跨帧目标之间的数据关联来形成轨迹，数据关联时身份嵌入（identity embedding）常被用来衡量两个目标的相似性。这种二阶段的策略揭示了两种改进跟踪性能的方式，一种是增强检测，一种则是增强基于embedding的数据关联。

大多数现有的在线方法通常只解决这两个方面中的一个以获得更好的跟踪结果，然而目前跟踪中最常见的挑战之一，**遮挡**，会对这两个方面都造成影响。非预期的遮挡会由于目标的重叠而出现误检，这同时也增加了关联的难度。很多在线跟踪方法都通过预测被跟踪目标的新位置来填补遮挡期间检测的空白，而也有不少研究侧重于生成更可区分的嵌入来在整个遮挡期间关联。尽管最近的一些工作试图同时解决这两个问题，但位置预测和嵌入关联仍被视为两个单独的任务，如何使它们相互受益尚未得到很好的探索。

常见的预测方法很少考虑对象之间的交互，因此在处理遮挡时位置预测是不够强的。在严重遮挡下做的预测可能会导致边界框漂移，即目标的预测位置开始跟随一个邻近的目标，然后由于边界框预测出错提取的嵌入也开始恶化，最终导致帧间关联错误。这种情况下，进行预测反而会对嵌入造成损害，而且，仅仅改善嵌入也只能减少关联阶段的错误而不能阻止位置预测的错误。也就是说，这类方法都是将位置预测和嵌入关联视作两个独立的问题，它们之间没有真正的协同作用。如下图(a)所示，位置预测和嵌入关联并没有在遮挡时从彼此中受益，随着跟踪的进行，目标的位置预测发生了漂移，提取的嵌入也含有了噪声。

![](https://i.loli.net/2021/06/24/xmrluZJCG8gb7kW.png)

在这篇论文中，作者提出了一个统一的模型，将位置预测和嵌入关联联合优化彼此受益，增强了跟踪对于遮挡的鲁棒性并改善了跟踪的性能。为了实现真正的协同作用，作者让一个任务参与到另一个任务的过程中，这两个任务通过由目标注意力模块和干扰注意力模块以及判别性记忆聚合组成的链接桥接在一起。针对关联优化的身份嵌入不仅用于计算亲和度，还用于生成对目标的关注以及通过注意力模块抑制漂移。通过这种方式，位置预测配备了身份感知能力并对附近的物体变得敏感，在更严重的遮挡下可以执行更正确的预测而不会发生漂移。通过在遮挡期间更好的预测和对目标的关注，可以提取更高质量的嵌入。 这种更可靠的嵌入然后参与注意力生成以更好地关注目标。因此，位置预测和嵌入关联相互关联，从而形成互惠互利的正反馈循环。 身份感知记忆聚合进一步放大了协同作用，因为随着时间的推移积累的更丰富的整体嵌入能够产生更强大的注意力。因此，在有遮挡的复杂场景中的跟踪性能得到了提升。我们在统一的端到端模型下联合优化位置预测、嵌入关联和所有提出的模块。**据作者所知，这篇论文是第一个在这两个任务上实现协同联合优化的。** 大体的思路如上图的(b)，上面的叙述还是比较多的，下面做一个简单的总结。

- 提出了一个统一的在线 MOT 模型，该模型在位置预测和嵌入关联之间带来了相互增益，从而实现了对遮挡的更强鲁棒性。
- 应用时间感知目标注意力和干扰注意力以及身份感知记忆聚合来链接这两个任务。
- 构建的TADAM跟踪器在MOTChallenge基准上获得了SOTA表现。

## TADAM

作者设计了一个统一的模型，在位置预测和数据关联之间带来相互增益，从而增强了对遮挡的鲁棒性并提高了跟踪性能。为了实现这一点，作者引入了**时间感知目标注意力和干扰物注意力**以更好地关注目标并抑制干扰物的干扰，以及**身份感知记忆聚合**方案以生成更强大的注意力。作者将其根据设计的组件命名为TADAM，这里TA和DA而非你别表示目标注意力（target attention）和干扰物注意力（distractor attention），M则表示记忆聚合（memory aggregation）。上述提到的所有组件均使用同一个数据源统一训练，整个框架如下图所示，**这一整节的叙述对照这个图理解起来会方便一些**。

![](https://i.loli.net/2021/06/24/OmTDZzsaFVuvUQL.png)

在进行后面的阐述之前，先对问题做一下简单的描述。一个被跟踪的目标在当前$t$帧之前的轨迹可以记作$T_{t-1}^{ta}$，它在第$t-1$帧上的边框可以记为$B_{t-1}^{ta}$。其附近的一个干扰物可以描述为$T_{t-1}^{di}$，其在$t-1$帧上的边界框相应的为$B_{t-1}^{di}$。$F_t^{ta}$表示的是这个目标在帧$t$上预测位置处根据边框$B_{t-1}^{ta}$提取得到的特征。$E_t^{ta}$和$E_t^{di}$表示目标及其干扰物当前帧上的身份嵌入，它们的历史嵌入参考则表示为$E_r^{ta}$和$E_r^{di}$。

### 位置预测

作者采用Tracktor作为baseline，这是一个基于回归的位置预测跟踪器，它优于其他基于视觉线索的预测方法。该方法首先训练一个二阶段的Faster R-CNN检测器，其中RPN被训练用于粗糙的proposal框的生成，一个回归head和分类head被训练用于调整边框和推断框内目标的类别。在跟踪时，第一个阶段的RPN会被丢弃，利用训练好的回归head从其先前位置$B_{t-1}^{ta}$得到预测特征$F_t^{ta}$来预测目标的新位置$B_t^{ta}$，分类head给出对应的置信度。上面框架图的(a)部分若不和其他部分相连，则描述了这种基于位置预测的跟踪过程。$E_t^{ta}$表示用于关联的嵌入，它随后在嵌入提取步骤获得。位置预测的能力主要来自于用给定的不太准确的框推断紧密拟合的边界框，并采用Faster R-CNN中的四个边的位移的smooth L1损失来训练，分类head则通过交叉熵来训练。这种位置预测方法摆脱了主动跟踪目标的数据关联，而通过匈牙利算法进行匹配仍然需要通过比较身份嵌入来搜索新检测中丢失目标的重新出现。**这篇论文提出的方法目的在于在位置预测设计之上带来跨任务协同作用。**

### 时间感知目标注意力和干扰物注意力

当对目标$T^{ta}$从$t-1$帧到$t$帧进行位置预测时，预测特征$F_t^{ta}$是根据目标之前的边框$B_{t-1}^{ta}$再第$t$帧上提取得到的，目标的新位置则通过$F_t^{ta}$预测得到。但是，当一个干扰物$T^{di}$离目标很近并且其边界框$B_{t-1}^{di}$和目标边界框$B_{t-1}^{ta}$有较大的重叠的时候，做出一个正确的预测可能是很难的。假定$T^{ta}$被$T^{di}$遮挡，即$T^{di}$在目标的前面，那么预测的边框$T^{ta}$将更接近$T^{di}$，这是因为$F_t^{ta}$的很大一部分来自$F_t^{di}$，而这些特征实际上属于$T^{di}$。在这种场景下的连续位置预测可能会导致$B_t^{ta}$逐步偏移向$B_t^{di}$。

为了克服这个问题，作者引入了一个target-attention（TA）模块来增强$F_t^{ta}$中属于$T^{ta}$的区域，以及一个distractor-attention（DA）模块来抑制$F_t^{ta}$中属于$T^{di}$的部分。target attention由目标最新的原始身份嵌入$E_t^{ta}$和目标的历史聚合嵌入参考$E_r^{ta}$计算得到，而distractor attention则依据$E_t^{di}$和干扰物遮挡参考$E_r^{di}$计算得到。为了简单，一个跟踪目标的干扰物选为其附近与其有最大IoU的另一个目标。这两个注意力作用于特征$F_t^{ta}$可以获得一个调整后的预测特征$\tilde{F}_{t}^{t a}$，因而可以生成$B_t^{ta}$的一个更好的位置预测。为了进一步加强注意力模块的鲁棒性，一个判别性记忆聚合被设计用来随时间提供目标的聚合引用，以使得注意力模块具有判别性和时间感知能力，该模块的细节下文会阐述。

为了增强或者抑制$F_t^{ta}$中的一些区域，计算从参考嵌入$E_r^{ta}$投影到新提取的原始嵌入$E_t^{ta}$的注意力。嵌入的维度为$\mathcal{R}^{C \times H \times W}$，$E_{t_{i}}^{t a}$和$E_{r_{j}}^{t a}$表示$E_t^{ta}$和$E_r^{ta}$上空间上的某个点，因此维度为$\mathcal{R}^{C}$，不难知道$i, j \in[1, H W]$。判别性聚合目标参考嵌入$E_{r_{j}}^{t a}$作为输入（如何获得这个参考嵌入下一节详解），一个从历史记忆参考$E_{r_{j}}^{t a}$到$E_{t_{i}}^{t a}$的聚合non-local目标注意力可以形式上表述如下，其中$\theta$和$\phi$是计算两者相关性的卷积层，$\rho$则是另一个用于生成$E_{r_{j}}^{t a}$输出representation的卷积层。

$$
f\left(E_{t_{i}}^{t a}, E_{r_{j}}^{t a}\right)=\theta\left(E_{t_{i}}^{t a}\right) \phi\left(E_{r_{j}}^{t a}\right) \rho\left(E_{r_{j}}^{t a}\right)
$$

通过序列化$E_{r_{j}}^{t a}$上的$j$和$E_{t_{i}}^{t a}$上的$i$之间的所有位置对，可以获得从参考$E_{r}^{t a}$到新嵌入$E_{t}^{t a}$的整体非局部注意力。由于$E_{r}^{t a}$是具有身份感知记忆的聚合，因此这个过程成为了目标历史参考和当前帧嵌入之间的判别性聚合非局部注意力。

类似的，判别性聚合非局部干扰物注意力按照下式求得。

$$
g\left(E_{t_{i}}^{t a}, E_{r_{j}}^{d i}\right)=\theta\left(E_{t_{i}}^{t a}\right) \phi\left(E_{r_{j}}^{d i}\right) \rho\left(E_{r_{j}}^{d i}\right)
$$

目标注意力中具有较大值的位置，那么这些部分更可能属于目标，而干扰注意力中具有较大值的位置，这些区域则更有可能属于干扰物。因此可以使用下面的式子精细调整特征图，得到$\tilde{F}_{t}^{t a}$，其中$f$和$g$表示两个注意力计算的向量化版本，$\oplus$和$\ominus$则表示逐元素相加和相减，$w$表示一个用于调节注意力输出值的权重，$E_{t}^{t a}$是当前帧上的嵌入，$E_{r}^{t a}$和$E_{r}^{d i}$则是从相应的记忆中取得的判别性目标参考和干扰参考。

$$
\tilde{F}_{t}^{t a}=F_{t}^{t a} \oplus w\left[f\left(E_{t}^{t a}, E_{r}^{t a}\right) \ominus g\left(E_{t}^{t a}, E_{r}^{d i}\right)\right]
$$

这两个注意力的组合在整个框架图上如(b)部分所示，使用上面注意力后的$\tilde{F}_{t}^{t a}$来进行位置预测，目标的位置$B_t^{ta}$可以在更多关注目标更少关注干扰的前提下完成。因此，在较重的遮挡下可以做出更正确的预测，从而可以为数据关联和记忆聚合收集噪声更少的身份嵌入，这在下一小节阐述。

下面，来补充一下这个注意力使用的时候的问题。**虽然来自TA的增强和来自DA的抑制使位置预测更加集中和更少分心，但它们对于简单的情况不一定有用，尤其是在几乎没有遮挡的目标上。** 因此，在上面整个注意力公式中使用一个固定的权重$w$来控制所有程度遮挡下的注意力输出，显然是次优的。经历严重遮挡的目标应该期待更大的增强和更强的抑制，而那些与邻居几乎没有重叠的目标应该保持原样，不进行处理。因此，为了解决这个问题，一个对于目标注意力和遮挡注意力的自适应权重被设计如下，其中$iou(,)$表示两个框的交并比，$B_t^{ta}$表示目标框，$B_t^{di}$表示相应的干扰框，$o_{\min }$表示加权生效的最小重叠值，$max(,)$表示两个输入的最大值。

$$
w=\frac{\max \left(i o u\left(B_{t}^{t a}, B_{t}^{d i}\right)-o_{\min }, 0\right)}{1-o_{\min }}
$$

可以发现，当目标和干扰物IoU大于$o_{min}$时上述权重非零且在0和1之间取值，否则上述权重为0。在参与进一步细化之前，目标注意力和干扰注意力的输出由这个权重自适应地调节。也就是说，目标注意力和干扰注意力不参与简单情况，而它们的大部分结果用于处理更严重的情形。

### 身份感知记忆聚合

在上一节中的两个注意力过程中，分别使用了目标参考嵌入和干扰参考嵌入，那么这个参考嵌入如何得到呢？一个直观且方便的方法是存储在前一帧中形成的嵌入来获取参考嵌入，但是在具有较重遮挡的复杂场景中，以这种方法获得的嵌入通常会存在噪声。为了增强注意力计算的鲁棒性，作者提出了一种**身份感知记忆聚合（identity-aware memory aggregation）** 来累积更多整体参考嵌入作为TA和DA模块的输入，这样可以进一步增强位置预测和嵌入提取。这部分的内容对应上面框架图的(c)部分。

在每一帧上，TA和DA使用当前帧的原始目标嵌入$E_t^{ta}$来生成修正后的特征$\tilde{F}_{t}^{t a}$。类似的，$E_t^{ta}$也被注意力处理为修正后的嵌入$\tilde{E}_{t}^{t a}$用于关联和聚合，这个过程和$\tilde{F}_{t}^{t a}$生成公式类似。由于要聚合的$\tilde{E}_{t}^{t a}$的维度为$\mathcal{R}^{C \times H \times W}$，聚合后产生的参考特征需要空间维度进行attention计算，所以我们必须保留聚合前后的空间信息。此外，对于整体聚合，聚合应该能够自动确定输入是否值得更新，而不是存储每个输入的累积。为了解决这些问题，我们设计了一个带有卷积门控循环单元 (GRU) 的判别性记忆模块，其中 GRU 中的矩阵乘法被卷积替换。这为跨帧的时间关系建立了记忆并保持了空间维度。聚合嵌入记忆的更新用下式进行描述，这个$update()$为记忆更新函数，$E_{r_{t-1}}$表示之前的记忆状态，$E_{r_{t}}$表示使用$\tilde{E}_{t}$和$E_{r_{t-1}}$更新得到的聚合嵌入。这个公式同时适用于目标和干扰，$update()$和GRU论文中状态计算一致，只不过点积换成了卷积以适用于二维输入。

$$
E_{r_{t}}=\operatorname{update}\left(\tilde{E}_{t}, E_{r_{t-1}}\right)
$$

从各自的记忆中检索到的目标参考嵌入和干扰参考嵌入需要在它们的嵌入空间中很好地分离。否则，注意力模块的输出不会对指定位置产生正确的注意力，而是会在属于任何对象的区域之间产生相似级别的响应。同时，由于用于数据关联的嵌入最初需要在没有聚合的情况下可区分，当然希望所有嵌入在内存聚合之前和之后都能区分身份。为此，作者采用一个联合判别性学习过程来优化时间聚合和嵌入生成。从骨干网络提取的目标嵌入首先经过四个状态初始化卷积层，这使得它可以区分不同的id。如果它不是序列中的第一个嵌入，那么就用上面的公式更新它以进行后续的聚合以及判别性学习。上述两个过程使用两个判别性id损失联合训练，一个交叉熵损失计算预测id和真实id之间的差距，另一个三元组损失用于最大化不同id间的差异同时最小化相同id内的差异。

当给定长度为 1 的输入进行聚合时，实际上获得了没有实际聚合的结果嵌入。 因此，可以通过提供single-length输入，将记忆模块用作框架中的嵌入提取方法。 随着同一个目标的输入变长，记忆聚合不断生成聚合的判别性嵌入。 通过这种方式，就可以实现记忆聚合和嵌入提取的联合优化。

最后，来整体回顾TADAM框架是如何做到任务间的协同作用的。通过聚合判别性嵌入，可以在关注目标和抑制干扰的注意力模块中获得更正确的注意力。在位置预测中应用注意力会导致更强的漂移抵抗力。 相反，在复杂场景中使用更正确和更长的预测边界框，我们可以积累更多由注意力模块细化的嵌入，并通过聚合为它们提供更可靠的表示。**因此，本节第二小节描述的时间感知目标注意力和干扰注意力和本节第三小节描述的身份感知时间聚合紧密协作，形成位置预测和嵌入关联之间的联系，从而带来跨任务的协同作用。**

## 实验

作者在MOT16和MOT17以及MOT20的public赛道上和其他方法比较，证明了TADAM的SOTA性能（注意是public赛道的SOTA），结果如下表所示。

![](https://i.loli.net/2021/06/24/X7cReDTZgvohGSM.png)

文中还列了不少消融实验，包括各个模块的有效性验证等，下图是相比于baseline所提出的TADAM在遮挡处理能力上的比较，可以看到，在遮挡等级较高的情况下是非常具有优势的。

![](https://i.loli.net/2021/06/24/GlrOpKL7BQHT8Sb.png)

## 总结

这篇文章中，作者设计了一种联合优化位置预测和嵌入关联的MOT新方法，通过目标注意力和遮挡注意力以及时间感知记忆聚合实现了两个任务的协同作用，取得了相当不错的表现，也被收录于CVPR2021，是很值得关注的工作。本文也只是我本人从自身出发对这篇文章进行的解读，想要更详细理解的强烈推荐阅读原论文。最后，如果我的文章对你有所帮助，欢迎一键三连，你的支持是我不懈创作的动力。