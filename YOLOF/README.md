# YOLOF解读

> 这是收录于CVPR2021的一篇目标检测的文章，标题也很有意思You Only Look One-level Feature，简称YOLOF，虽然和YOLO没啥关系，针对FPN做的一个工作，理论创新性还是蛮大的，这篇文章对我比较大的触动就是，很多我们习以为常的东西背后其实有着和我们预期不一样的原理，发现并且改进它是非常难得的。

## 简介

众所周知，FPN和Focal Loss为单阶段目标检测和anchor-free目标检测做出了巨大贡献，但是YOLOF这篇论文指出FPN最成功之处在于将优化问题分治的策略而不是多尺度特征融合。从优化的角度来看，作者引入了一种解决该优化问题的替代方案而无需使用复杂的特征金字塔，只需要使用单层特征图。基于这个简单高效的方案，作者设计了You Only Look One-level Feature（YOLOF）检测框架。在该框架中，有两个核心组件，分别是膨胀编码器（Dilated Encoder）和均衡匹配策略（Uniform Matching），它们带来了巨大的性能提升。COCO数据集上的实验证明了YOLOF的有效性，它获得了和有特征金字塔版本相当的结果但是速度快了2.5倍。此外，在没有Transformer层的前提下，YOLOF可以和同样使用单层特征图的DETR媲美且训练轮次少了7倍。

- 论文标题

    You Only Look One-level Feature
- 论文地址

    https://arxiv.org/abs/2103.09460
- 论文源码

    https://github.com/megvii-model/YOLOF

## 介绍

不可否认，在二阶段和单阶段的SOTA检测器中，特征金字塔已经成为了一个非常重要的组件，而构建特征金字塔当前最流行的选择是使用特征金字塔网络（Feature Pyramid Networks，FPN），这个网络我在[之前的文章](https://zhouchen.blog.csdn.net/article/details/114790604)已经介绍过了。FPN主要有两个核心的收益：一方面，FPN可以进行**多尺度特征融合**，它将多个尺度的特征图融合在一起获得更好的表示；另一方面，它又是一种**分治策略**，依据目标的不同尺度在不同级别的特征图上检测目标。

![](https://i.loli.net/2021/03/24/ADRnshWMyd2Ufiz.png)

此前一般认为，FPN的成功之处在于进行了多级特征的融合，这引发了一系列人工设计或者NAS搜索更加复杂融合方法的研究，如EfficientDet中的BiFPN。遗憾的是，这种观念忽视了FPN分治的功能，这就导致很少有研究研究这两个收益对FPN的成功贡献究竟如何，也一定程度上阻碍了目标检测领域新的进展。

这篇论文就是针对FPN在单阶段检测器中这两个收益的。作者在RetinaNet的基础上通过解耦多尺度特征融合和分治功能设计了实验。具体而言，将FPN视作一个**多进多出（Multiple-in-Multiple-out，MiMo）编码器**，它从骨干网络编码多尺度特征并且为解码器即检测head提供特征表示。作者对MiMo（多进多出）、单进多出（SiMo）、多进单出（MiSo）和单进单出（SiSo）编码器进行了对比实验，结果如下图。

![](https://i.loli.net/2021/03/24/5OcBk3FqKvpgjlY.png)

上图可以发现一个令人惊讶的事实，SiMo编码器几乎可以获得和MiMo编码器（如FPN）相当的表现，注意，它只使用了C5特征图没有使用多层特征融合，它们之间的差距只有1 mAP左右。相比之下，MiSo和SiSo结构则有非常大的性能下降。**这些实验结果表明两个事实：第一，C5特征图上其实就包含了检测各种尺度目标的足够的上下文信息，这就导致SiMo编码器可以获得相当不错的效果；第二，多尺度特征融合带来的收益要远远小于分治策略带来的收益，因此多尺度特征融合在FPN不是最关键的功能。** 进而更深入思考分治策略，其实它对应目标检测中的优化问题，它将复杂的目标检测问题依据目标尺度分解为几个子问题，促进了优化过程。

上面的分析说明，FPN关键的成功因素其实是对目标检测优化问题的解决方案，分治策略是一个好的方式，然而，它也带来了比较大的内存负担，降低了检测器速度并且使得单阶段检测器的结构比较复杂。考虑到C5特征图其实已经包含了足够的信息用于目标检测，那么有没有更加优雅的方式处理优化问题呢？这就诞生了这篇论文提出的**You Only Look One-level Feature（YOLOF）**，这是一个新的只使用32倍下采样的C5特征图的目标检测框架。为了弥补SiSo编码器和MiMo编码器之间的性能差距，作者首先对编码器的结构进行了适当的设计，以提取不同尺度目标的多尺度上下文特征，弥补多尺度特征的不足；然后，作者采用均衡匹配机制来解决单特征图中稀疏anchor引起的正样本不平衡问题。

## MiMo编码器分析

上一节提到了FPN的成功之处在于优化问题的处理方案，但是这种多层特征图的处理方式不可避免使得检测器更加复杂，增加内存开销减慢检测器速度。所以，论文中作者先对MiMo编码器代价进行了一个定量分析。基于RetinaNet，将检测任务的pipeline分为三个部分：backbone、encoder（编码器）、decoder（解码器），如下图所示。

![](https://i.loli.net/2021/03/24/x9YyXcJFqSD3ZpL.png)

对这三个组件分别实验，得到下图所示的结果。首先看左边的纵轴，它表示FLOPs，可以看到相比于SiSo结构，MiMo结构给编码器和解码器带来了巨大的内存开销。再看右边的纵轴，它表示模型推理的速度，MiMo结构同样比SiSo慢了很多，这个低速来源于高分辨率特征图（C3）上进行目标检测。

![](https://i.loli.net/2021/03/24/kLXNqO2eZV8B5rE.png)

既然有这么大的劣势，那么自然想设计一种MiMo结构解决优化问题的替代方案，这个方案还要同时保证检测器的简单高效精度高，这就有了下一节方法。

## 方法

设计一个SiSo结构取代MiMo结构是本文的出发点，但是这种替换绝非易事，因为上面的实验结果已经表明将MiMo直接换为SiSo会引起巨大的性能下降。作者对此进行了详细分析，发现主要是两个原因造成了这种性能上的大幅度下降：第一，与C5特征图感受野匹配的**目标尺度范围是有限的**，这阻碍了不同尺度目标的检测表现；第二，由于单级特征图上稀疏anchor生成策略造成的**正样本不均衡问题**。下文会具体讨论这两个问题并并且提供论文给出的解决方案。

### 受限尺度范围

检测尺度变化范围较大的目标在目标检测领域是个比较重要的问题，一个可行的方案就是利用多级特征图。在MiMo结构和SiMo结构中，它们从不同感受野（P3-P7）的特征图构建多级特征并在和感受野匹配的尺度的感受野级别特征图上进行目标的检测。但是，单级别特征图使得玩法变得不一样了，SiSo结构中只会输出固定感受野的单级别的特征图。如下图的(a)所示，C5级别的特征图只能覆盖一个受限的感受野，当目标的尺度和感受野不匹配时，检测效果就会很差。

![](https://i.loli.net/2021/03/24/ByTZFxCgM7H4pNX.png)

因此，必须找到一个方案让SiSo结构输出多感受野的特征图。作者首先通过堆叠标准卷积和膨胀卷积增大感受野。这样，虽然覆盖尺度范围得到了一定程度的扩大，但仍然不能覆盖所有的目标尺度，因为扩大过程相当于将一个大于1的因子乘以原来覆盖的所有尺度。这个策略可以通过上图的(b)来可视化，它其实是发生了偏移和扩大。此时，将原始特征图和扩大感受野的特征图加到一起，就能得到覆盖所有目标尺度的特征图了，如上图的(c)所示。这个过程其实可以通过残差连接构造膨胀模块实现，称为Dilated Encoder。

![](https://i.loli.net/2021/03/24/XRsVQWeYd3gy6jw.png)

基于上面的讨论，作者设计了如上图所示的SiSo结构，名为**Dilated Encoder**。它包含先后两个组件，分别是Projector和Residual Blocks。投影层首先应用一个1×1的卷积层来降低通道维数，然后添加一个3×3卷积层来细化上下文语义信息，这与FPN一致。然后，叠加连续4个卷积核膨胀率不同的残差块，生成具有多个感受野的输出特征，覆盖所有对象的尺度。

### 正样本不均衡

正样本的定义对于目标检测问题的优化至关重要，在anchor-based方法中，正样本的定义是基于anchor和GT框之间的IoU进行的，在RetinaNet中，如果一个anchor和GT框之间的最大IoU大于一个给定的阈值，这个anchor就是一个正样本。这个策略称为**Max-IoU匹配**。

在MiMo结构中，anchor以一个密集平铺的方式在多层特征图上预定义，GT框根据尺度在不同级别的特征图上产生正样本。在分治策略下，Max-IoU匹配使各尺度的Gt框可以产生足够数量的正anchor（上述的正样本）。然而，当采用SiSo编码器时，anchor的数量比MiMo编码器中的anchor的数量减少了很多，从100k减少到5k，导致anchor是非常稀疏的。对稀疏的anchor采用Max-IoU匹配会引起一个问题，如下图所示，大GT框比小GT框会产生更多的正anchor，从而造成了正anchor的不平衡问题。这会导致检测器只关注大目标的训练，而忽略小目标检测的优化。

![](https://i.loli.net/2021/03/24/MEw2htJSfdl7gFx.png)

因此，作者设计了一个均衡匹配（Uniform Matching）策略，即对每个GT框而言，只采用最接近的k个anchor作为正anchor，这就能如上图一样保证每个GT框不论尺寸大小都有相同数目的正anchor。平衡的正样本确保所有的GT框平等地参与训练。同样，作者也设置阈值来过滤大IoU的负样本和小IoU的正样本。

### YOLOF

基于上述的两种解决方案，作者提出了一种只使用单级别特征图的简单目标检测框架，YOLOF，它包含三个主要部分：backbone、encoder、decoder。

![](https://i.loli.net/2021/03/24/A4JzTmEBFrhu2xs.png)

backbone作者还是采用经典的ResNet和ResNeXt，选取的特征图是C5，通道数为2048且下采样率为32。关于encoder的大致思路，上面已经说明了，这里详细说一下结构。首先，和FPN类似，对backbone的输出使用两个投影层（由1x1卷积和3x3卷积组成），得到通道数为512的特征图。然后，为了获得全尺度感受野，作者这里使用了一种残差模块，它由三个卷积组成，第一个1x1卷积通道减少4倍，然后一个3x3膨胀卷积用于增大感受野，最后的1x1卷积恢复通道维度，这个残差块会重复四次。

至于decoder，则和RetinaNet类似，它包含两个并行的head分支，用于目标分类和边框回归任务。作者这里主要做了两个改动，第一，是按照DETR中FFN的设计，使得两个head卷积层数目不同。在回归分支中，是四个卷积层加上BN层和ReLU层，而在分类分支中只有两个卷积层。第二，依据Autoassign，为回归分支的每个anchor增加一个隐式的objectness（没有直接监督），最终的分类置信度由分类分支的输出和objectness得分相乘得到。

此外，作者还做了一些类似数据增强等策略，这里就不细说了，感兴趣可以参考原论文。

## 实验

首先是和RetinaNet进行比较，作者这里对RetinaNet做了加强以公平比较，实验结果如下图，精度和速度提升是非常恐怖的。

![](https://i.loli.net/2021/03/24/pY3hXQfvSRCT5Pm.png)

也和DETR以及YOLOv4进行了对比，结果如下。

![](https://i.loli.net/2021/03/24/swPTIhFDXMq41xe.png)

![](https://i.loli.net/2021/03/24/xIHOm52gaJPuMhV.png)

此外，作者也进行了各个模块有效性的消融实验，我这里就不贴了，感兴趣可以查看原论文。

## 总结

这篇文章详细分析了FPN成功的核心因素是分治策略，并提出使用单级特征图进行处理的设计方案，YOLOF，是非常具有开创性和理论意义的工作，指的了解。本文也只是我本人从自身出发对这篇文章进行的解读，想要更详细理解的强烈推荐阅读原论文。最后，如果我的文章对你有所帮助，欢迎一键三连，你的支持是我不懈创作的动力。